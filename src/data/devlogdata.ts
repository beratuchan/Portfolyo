// Ã–rnek veri - daha sonra ayrÄ± dosyadan import edebilirsiniz
import finalresults from "../assets/bloggorsel/final-results.png"
import frontendarchitecture from "../assets/bloggorsel/frontend-architecture.png"
import architecturediagram from "../assets/bloggorsel/architecture-diagram.png"
import datapipeline from "../assets/bloggorsel/data-pipeline.png"
import mlopspipeline from "../assets/bloggorsel/mlops-pipeline.png"
import duygufinetune from "../assets/bloggorsel/duygu-finetune.png"
import monolith from "../assets/bloggorsel/monolith.png"
import spark from "../assets/bloggorsel/spark.png"
import mlopskapak from "../assets/bloggorsel/mlopskapak.png"

import type {DevlogContent } from "../types/devlog";


export const devlogData: DevlogContent[] = [
  {
    id: 1,
    title: "ChatAssist'te Duygu Analizi Modelini Fine-tune Etmek",
    date: "25 Ekim 2025",
    author: "Deniz YÄ±lmaz",
    coverImage: duygufinetune,
    content: [
      {
        type: 'paragraph',
        content: "ChatAssist'in mÃ¼ÅŸteri mesajlarÄ±nÄ± analiz eden modÃ¼lÃ¼nÃ¼ geliÅŸtirirken, Ã§ok dilli duygu tespiti bizim iÃ§in en zorlu ama en keyifli bÃ¶lÃ¼mlerden biriydi. Bu yazÄ±da, modelimizi nasÄ±l Ã¶zelleÅŸtirdiÄŸimizi ve elde ettiÄŸimiz sonuÃ§larÄ± adÄ±m adÄ±m paylaÅŸacaÄŸÄ±m."
      },
      {
        type: 'heading',
        level: 2,
        text: "1ï¸âƒ£ Veri Seti ve Temizlik SÃ¼reci",
        className: "text-2xl font-semibold bg-gradient-to-r from-cyan-600 to-rose-500 bg-clip-text text-transparent mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Ä°lk adÄ±m olarak, farklÄ± dillerden gelen 50.000 mÃ¼ÅŸteri mesajÄ±nÄ± etiketledik. Her mesaj 'olumlu', 'nÃ¶tr' veya 'olumsuz' kategorilerinden birine ait."
      },
      {
        type: 'code',
        language: "python",
        code: `import pandas as pd

df = pd.read_csv("customer_feedback.csv")
df["text"] = df["text"].str.lower().str.replace(r"[^a-zÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°0-9 ]", "")
df.dropna(subset=["text", "sentiment"], inplace=True)`
      },
      {
        type: 'heading',
        level: 2,
        text: "2ï¸âƒ£ Model Mimarisinin SeÃ§ilmesi",
        className: "text-2xl font-semibold bg-gradient-to-r from-cyan-600 to-rose-500 bg-clip-text text-transparent mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Multilingual yapÄ±yÄ± desteklediÄŸi iÃ§in BERT-base-multilingual-cased modelini kullandÄ±k. Bu model TÃ¼rkÃ§e, Ä°ngilizce, FransÄ±zca ve Ä°spanyolca dahil 104 dili destekliyor."
      },
      {
        type: 'code',
        language: "python",
        code: `from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("bert-base-multilingual-cased")
model = AutoModelForSequenceClassification.from_pretrained(
    "bert-base-multilingual-cased",
    num_labels=3
)`
      },
      {
        type: 'heading',
        level: 2,
        text: "3ï¸âƒ£ Fine-tuning ve SonuÃ§lar",
        className: "text-2xl font-semibold bg-gradient-to-r from-cyan-600 to-rose-500 bg-clip-text text-transparent mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Modeli 3 epoch boyunca eÄŸittik. Ã–ÄŸrenme oranÄ±nÄ± 2e-5 olarak tuttuk ve mini-batch boyutu 16 idi. EÄŸitim sonunda model doÄŸruluÄŸu %91.2'ye ulaÅŸtÄ±."
      },
      {
        type: 'table',
        headers: ["Etiket", "Precision", "Recall", "F1 Score"],
        rows: [
          ["Olumlu", "0.93", "0.90", "0.91"],
          ["Olumsuz", "0.89", "0.92", "0.90"],
          ["NÃ¶tr", "0.90", "0.91", "0.90"]
        ]
      },
      {
        type: 'heading',
        level: 2,
        text: "ğŸš€ SonuÃ§ ve Gelecek PlanlarÄ±",
        className: "text-2xl font-semibold bg-gradient-to-r from-cyan-600 to-rose-500 bg-clip-text text-transparent mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Fine-tune edilmiÅŸ model, ChatAssist'in kullanÄ±cÄ± yanÄ±tlarÄ±nÄ± daha 'empatik' hale getirmesini saÄŸladÄ±. Gelecekte, duygusal tonlamayÄ± sesli yanÄ±tlar ve avatar mimikleriyle senkronize etmek gibi ek planlarÄ±mÄ±z var."
      },
      {
        type: 'image',
        src: finalresults,
        alt: "ChatAssist arayÃ¼zÃ¼nde duygu analizi",
        caption: "Åekil 4. ChatAssist arayÃ¼zÃ¼nde duygu analizi Ã§Ä±ktÄ±sÄ±"
      }
    ]
  },

  {
    id: 2,
    title: "Microservices Mimarisine GeÃ§iÅŸ: Monolith'ten Cloud-Native'e Yolculuk",
    date: "15 KasÄ±m 2025",
    author: "Deniz YÄ±lmaz",
    coverImage: monolith,
    content: [
      {
        type: 'paragraph',
        content: "TrendTech bÃ¼nyesinde geliÅŸtirdiÄŸimiz monolith uygulamasÄ±nÄ± microservices mimarisine taÅŸÄ±rken yaÅŸadÄ±ÄŸÄ±mÄ±z teknik zorluklar ve Ã§Ã¶zÃ¼m Ã¶nerilerini bu yazÄ±da paylaÅŸÄ±yorum. Bu dÃ¶nÃ¼ÅŸÃ¼m, sistem performansÄ±mÄ±zÄ± 5x artÄ±rÄ±rken deployment sÃ¼relerimizi %70 kÄ±salttÄ±."
      },
      {
        type: 'heading',
        level: 2,
        text: "1ï¸âƒ£ Monolith'in SÄ±nÄ±rlarÄ± ve GeÃ§iÅŸ KararÄ±",
        className: "text-2xl font-semibold text-blue-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Tek bir kod tabanÄ±yla Ã§alÄ±ÅŸmanÄ±n getirdiÄŸi deployment zorluklarÄ± ve scaling problemleri, bizi microservices'e geÃ§iÅŸ yapmaya zorladÄ±. Ã–zellikle trafik yoÄŸunluÄŸu arttÄ±ÄŸÄ±nda tÃ¼m sistemin etkilenmesi kabul edilemez bir risk haline gelmiÅŸti."
      },
      {
        type: 'code',
        language: "yaml",
        code: `# docker-compose.yml - Eski monolith yapÄ±
version: '3.8'
services:
  monolith-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/app
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis`
      },
      {
        type: 'heading',
        level: 2,
        text: "2ï¸âƒ£ Domain-Driven Design ile Servis AyrÄ±mÄ±",
        className: "text-2xl font-semibold text-blue-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Domain-Driven Design (DDD) prensiplerini kullanarak uygulamamÄ±zÄ± 6 ana domaine ayÄ±rdÄ±k: User Management, Order Processing, Payment, Inventory, Notification ve Analytics. Her domain kendi veritabanÄ±na ve business logic'ine sahip oldu."
      },
      {
        type: 'code',
        language: "typescript",
        code: `// Service discovery configuration
const serviceConfig = {
  userService: {
    url: process.env.USER_SERVICE_URL || 'http://user-service:3001',
    timeout: 5000
  },
  orderService: {
    url: process.env.ORDER_SERVICE_URL || 'http://order-service:3002',
    timeout: 8000
  },
  paymentService: {
    url: process.env.PAYMENT_SERVICE_URL || 'http://payment-service:3003',
    timeout: 10000
  }
};`
      },
      {
        type: 'heading',
        level: 2,
        text: "3ï¸âƒ£ Kubernetes ve Service Mesh Implementasyonu",
        className: "text-2xl font-semibold text-blue-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Kubernetes cluster'Ä±mÄ±zÄ± AWS EKS Ã¼zerinde kurduk ve Istio service mesh ile servisler arasÄ± iletiÅŸimi yÃ¶nettik. CanlÄ± trafikte yapÄ±lan A/B testleri sonucunda latency %40 azalÄ±rken error rate %85 iyileÅŸti."
      },
      {
        type: 'table',
        headers: ["Metrik", "Monolith", "Microservices", "Ä°yileÅŸme"],
        rows: [
          ["Ortalama Response Time", "450ms", "180ms", "%60"],
          ["Deployment Frequency", "Haftada 1", "GÃ¼nde 10+", "%900"],
          ["System Uptime", "99.2%", "99.95%", "%0.75"],
          ["Error Rate", "3.2%", "0.5%", "%85"]
        ]
      },
      {
        type: 'heading',
        level: 2,
        text: "ğŸš€ Elde Edilen KazanÄ±mlar ve Ã–ÄŸrenilen Dersler",
        className: "text-2xl font-semibold text-blue-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Microservices mimarisi bize Ã¶lÃ§eklenebilirlik ve hÄ±z kazandÄ±rsa da operasyonel karmaÅŸÄ±klÄ±ÄŸÄ± artÄ±rdÄ±. Distributed tracing, centralized logging ve comprehensive monitoring olmadan bu mimaride baÅŸarÄ±lÄ± olmak mÃ¼mkÃ¼n deÄŸil. Bir sonraki hedefimiz serverless computing'e geÃ§iÅŸ."
      },
      {
        type: 'image',
        src: architecturediagram,
        alt: "Microservices mimari diyagramÄ±",
        caption: "Åekil 2.1. Nihai microservices mimarimiz ve servis baÄŸÄ±mlÄ±lÄ±klarÄ±"
      }
    ]
  },
  {
    id: 3,
    title: "Real-time Data Processing: Apache Kafka ve Spark Streaming ile Ã–lÃ§eklenebilir Ã‡Ã¶zÃ¼m",
    date: "5 AralÄ±k 2025",
    author: "Deniz YÄ±lmaz",
    coverImage: spark,
    content: [
      {
        type: 'paragraph',
        content: "IoT Sensor Hub projemiz iÃ§in saniyede 50.000+ event'i iÅŸleyebilen real-time data processing pipeline'Ä±nÄ± nasÄ±l tasarladÄ±ÄŸÄ±mÄ±zÄ± anlatacaÄŸÄ±m. Bu sistem sayesinde predictive maintenance doÄŸruluÄŸumuzu %94'e Ã§Ä±kardÄ±k."
      },
      {
        type: 'heading',
        level: 2,
        text: "1ï¸âƒ£ Veri AkÄ±ÅŸÄ± Mimarisi ve Kafka Topology",
        className: "text-2xl font-semibold text-green-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "SensÃ¶rlerden gelen ham veriyi Kafka topics'lerine yÃ¶nlendirdik. Her sensÃ¶r tipi iÃ§in ayrÄ± topic'ler oluÅŸturarak veri izolasyonu saÄŸladÄ±k. Topic partitioning ile paralel iÅŸleme kapasitemizi artÄ±rdÄ±k."
      },
      {
        type: 'code',
        language: "java",
        code: `// Kafka producer configuration
Properties props = new Properties();
props.put("bootstrap.servers", "kafka-cluster:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("acks", "all");
props.put("retries", 3);
props.put("batch.size", 16384);
props.put("linger.ms", 10);`
      },
      {
        type: 'heading',
        level: 2,
        text: "2ï¸âƒ£ Spark Streaming ile Real-time Analytics",
        className: "text-2xl font-semibold text-green-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Spark Structured Streaming kullanarak Kafka'dan gelen verileri 30 saniyelik window'larda iÅŸledik. Anomali tespiti, trend analizi ve predictive maintenance modellerini real-time olarak Ã§alÄ±ÅŸtÄ±rdÄ±k."
      },
      {
        type: 'code',
        language: "scala",
        code: `val df = spark
  .readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "kafka-cluster:9092")
  .option("subscribe", "sensor-data")
  .load()

val processedData = df
  .select(from_json($"value", schema).as("data"))
  .withColumn("timestamp", to_timestamp($"data.timestamp"))
  .withWatermark("timestamp", "1 minute")
  .groupBy(
    window($"timestamp", "30 seconds"),
    $"data.sensor_type"
  )
  .agg(avg($"data.temperature").as("avg_temp"))`
      },
      {
        type: 'heading',
        level: 2,
        text: "3ï¸âƒ£ Performans Optimizasyonu ve Monitoring",
        className: "text-2xl font-semibold text-green-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Cluster resource allocation, memory tuning ve garbage collection optimizasyonlarÄ± ile sistem performansÄ±nÄ± maximize ettik. Prometheus ve Grafana ile real-time monitoring dashboard'u oluÅŸturduk."
      },
      {
        type: 'table',
        headers: ["Metrik", "BaÅŸlangÄ±Ã§", "Optimize EdilmiÅŸ", "Ä°yileÅŸme"],
        rows: [
          ["Event Processing Rate", "25k/s", "52k/s", "%108"],
          ["End-to-End Latency", "2.1s", "0.8s", "%62"],
          ["CPU Usage", "85%", "65%", "%24"],
          ["Memory Usage", "78%", "55%", "%30"]
        ]
      },
      {
        type: 'heading',
        level: 2,
        text: "ğŸš€ EndÃ¼stri 4.0'a HazÄ±r Real-time Platform",
        className: "text-2xl font-semibold text-green-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "GeliÅŸtirdiÄŸimiz real-time data processing pipeline'Ä± sayesinde mÃ¼ÅŸterilerimiz anlÄ±k makine performansÄ± takibi yapabiliyor, predictive maintenance ile plansÄ±z duruÅŸlarÄ± %90 azaltabiliyor. Bir sonraki adÄ±mÄ±mÄ±z edge computing ile daha da daÄŸÄ±tÄ±k bir mimariye geÃ§mek."
      },
      {
        type: 'image',
        src: datapipeline,
        alt: "Real-time data processing pipeline mimarisi",
        caption: "Åekil 3.1. End-to-end real-time data processing pipeline'Ä±mÄ±z"
      }
    ]
  },
  {
    id: 4,
    title: "React + TypeScript: Enterprise Seviyesinde Frontend Architecture Best Practices",
    date: "20 Ocak 2026",
    author: "Deniz YÄ±lmaz",
    coverImage: frontendarchitecture,
    content: [
      {
        type: 'paragraph',
        content: "BÃ¼yÃ¼k Ã¶lÃ§ekli React projelerinde karÅŸÄ±laÅŸtÄ±ÄŸÄ±mÄ±z state management, component organization ve performance sorunlarÄ±nÄ± nasÄ±l Ã§Ã¶zdÃ¼ÄŸÃ¼mÃ¼zÃ¼ paylaÅŸÄ±yorum. 100.000+ satÄ±r koda sahip frontend projemizde uyguladÄ±ÄŸÄ±mÄ±z best practices'ler."
      },
      {
        type: 'heading',
        level: 2,
        text: "1ï¸âƒ£ Atomic Design ve Component Architecture",
        className: "text-2xl font-semibold text-purple-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Atomic Design prensiplerini kullanarak component'larÄ±mÄ±zÄ± atoms, molecules, organisms ve templates ÅŸeklinde kategorize ettik. Bu sayede component reusability'yi maximize ederken technical debt'i minimize ettik."
      },
      {
        type: 'code',
        language: "typescript",
        code: `// Atomic Design structure
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ atoms/
â”‚   â”‚   â”œâ”€â”€ Button/
â”‚   â”‚   â”œâ”€â”€ Input/
â”‚   â”‚   â””â”€â”€ Typography/
â”‚   â”œâ”€â”€ molecules/
â”‚   â”‚   â”œâ”€â”€ SearchBar/
â”‚   â”‚   â””â”€â”€ UserProfile/
â”‚   â”œâ”€â”€ organisms/
â”‚   â”‚   â”œâ”€â”€ Header/
â”‚   â”‚   â””â”€â”€ Sidebar/
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ Dashboard/
â”‚       â””â”€â”€ Auth/
â”œâ”€â”€ hooks/
â”œâ”€â”€ utils/
â””â”€â”€ types/`
      },
      {
        type: 'heading',
        level: 2,
        text: "2ï¸âƒ£ Advanced State Management: Zustand + React Query",
        className: "text-2xl font-semibold text-purple-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Redux'Ä±n karmaÅŸÄ±klÄ±ÄŸÄ±ndan kurtulup Zustand ile client state'i, React Query ile server state'i yÃ¶nettik. Bu kombinasyon ile boilerplate kodunu %70 azaltÄ±rken developer experience'i Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirdik."
      },
      {
        type: 'code',
        language: "typescript",
        code: `// Zustand store example
import { create } from 'zustand'

interface AuthState {
  user: User | null
  login: (email: string, password: string) => Promise<void>
  logout: () => void
}

export const useAuthStore = create<AuthState>((set) => ({
  user: null,
  login: async (email, password) => {
    const user = await authAPI.login(email, password)
    set({ user })
  },
  logout: () => set({ user: null })
}))

// React Query hook
export const useUserData = (userId: string) => {
  return useQuery({
    queryKey: ['user', userId],
    queryFn: () => fetchUser(userId),
    staleTime: 5 * 60 * 1000 // 5 minutes
  })
}`
      },
      {
        type: 'heading',
        level: 2,
        text: "3ï¸âƒ£ Performance Optimization ve Bundle Analysis",
        className: "text-2xl font-semibold text-purple-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Code splitting, lazy loading ve memoization teknikleri ile initial bundle size'Ä± 2.1MB'tan 450KB'a dÃ¼ÅŸÃ¼rdÃ¼k. Lighthouse skorlarÄ±mÄ±zÄ± 65'ten 95'e Ã§Ä±kardÄ±k."
      },
      {
        type: 'table',
        headers: ["Performance Metrik", "Optimizasyon Ã–ncesi", "Optimizasyon SonrasÄ±", "Ä°yileÅŸme"],
        rows: [
          ["First Contentful Paint", "3.2s", "1.1s", "%66"],
          ["Largest Contentful Paint", "5.8s", "2.3s", "%60"],
          ["Cumulative Layout Shift", "0.25", "0.05", "%80"],
          ["Bundle Size", "2.1MB", "450KB", "%79"]
        ]
      },
      {
        type: 'heading',
        level: 2,
        text: "ğŸš€ Production Ready Frontend Architecture",
        className: "text-2xl font-semibold text-purple-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "GeliÅŸtirdiÄŸimiz architecture sayesinde 10+ developer'Ä±n aynÄ± codebase'de sorunsuz Ã§alÄ±ÅŸabildiÄŸi, test coverage'i %85'in Ã¼zerinde olan ve kullanÄ±cÄ± deneyimi aÃ§Ä±sÄ±ndan son derece performanslÄ± bir frontend uygulamasÄ±na sahip olduk. Bir sonraki hedefimiz WebAssembly ile daha da performanslÄ± computation'lar yapmak."
      },
      {
        type: 'image',
        src: architecturediagram,
        alt: "Frontend architecture diagram",
        caption: "Åekil 4.1. Enterprise React + TypeScript architecture'mÄ±z"
      }
    ]
  },
  {
    id: 5,
    title: "MLOps Pipeline: Machine Learning Modellerini Production'a TaÅŸÄ±mak",
    date: "10 Åubat 2026",
    author: "Deniz YÄ±lmaz",
    coverImage: mlopskapak,
    content: [
      {
        type: 'paragraph',
        content: "Machine learning modellerini research'ten production'a taÅŸÄ±rken karÅŸÄ±laÅŸtÄ±ÄŸÄ±mÄ±z zorluklarÄ± ve geliÅŸtirdiÄŸimiz end-to-end MLOps pipeline'Ä±nÄ± anlatÄ±yorum. Bu pipeline sayesinde model deployment sÃ¼remizi 2 haftadan 2 saate indirdik."
      },
      {
        type: 'heading',
        level: 2,
        text: "1ï¸âƒ£ End-to-End ML Pipeline: Data to Deployment",
        className: "text-2xl font-semibold text-orange-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "MLflow, Kubeflow ve Airflow kullanarak veri toplama, preprocessing, model training, evaluation ve deployment sÃ¼reÃ§lerini otomatize ettik. Her model version'Ä± iÃ§in experiment tracking ve model registry uyguladÄ±k."
      },
      {
        type: 'code',
        language: "python",
        code: `import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier

def train_model(X_train, y_train):
    with mlflow.start_run():
        # Model training
        model = RandomForestClassifier(n_estimators=100)
        model.fit(X_train, y_train)
        
        # Log parameters and metrics
        mlflow.log_param("n_estimators", 100)
        mlflow.log_metric("accuracy", model.score(X_test, y_test))
        
        # Log model
        mlflow.sklearn.log_model(model, "model")
        
        # Register model
        mlflow.register_model("runs:/{run_id}/model", "SentimentModel")`
      },
      {
        type: 'heading',
        level: 2,
        text: "2ï¸âƒ£ Model Serving ve A/B Testing Infrastructure",
        className: "text-2xl font-semibold text-orange-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "KServe (formerly KFServing) kullanarak model serving layer'Ä±nÄ± Kubernetes Ã¼zerinde kurduk. CanlÄ± trafikte A/B testing yapabilme ve shadow deployment Ã¶zellikleri ile riski minimize ettik."
      },
      {
        type: 'code',
        language: "yaml",
        code: `apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: sentiment-analysis
spec:
  predictor:
    canaryTrafficPercent: 20
    containers:
    - name: kserve-container
      image: registry/sentiment-model:v2
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"`
      },
      {
        type: 'heading',
        level: 2,
        text: "3ï¸âƒ£ Model Monitoring ve Data Drift Detection",
        className: "text-2xl font-semibold text-orange-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "Production'daki modellerimizi sÃ¼rekli monitor ederek accuracy decay, data drift ve concept drift'i tespit ediyoruz. Evidently AI kullanarak otomatik retraining trigger'larÄ± oluÅŸturduk."
      },
      {
        type: 'table',
        headers: ["Monitoring Metrik", "Threshold", "Alert Channel", "Action"],
        rows: [
          ["Prediction Accuracy", "< 90%", "Slack + PagerDuty", "Auto-retrain"],
          ["Data Drift Score", "> 0.2", "Email", "Data investigation"],
          ["Inference Latency", "> 500ms", "Slack", "Scale up"],
          ["Feature Drift", "> 0.15", "Dashboard", "Model update"]
        ]
      },
      {
        type: 'heading',
        level: 2,
        text: "ğŸš€ Full Otomasyon ile ML Model Lifecycle",
        className: "text-2xl font-semibold text-orange-400 mt-8 mb-3"
      },
      {
        type: 'paragraph',
        content: "KurduÄŸumuz MLOps pipeline sayesinde data scientist'ler sadece model geliÅŸtirmeye odaklanabiliyor, modeller otomatik olarak production'a taÅŸÄ±nÄ±yor ve performanslarÄ± sÃ¼rekli monitor ediliyor. Bir sonraki hedefimiz reinforcement learning modelleri iÃ§in benzer bir pipeline oluÅŸturmak."
      },
      {
        type: 'image',
        src: mlopspipeline,
        alt: "End-to-end MLOps pipeline diagram",
        caption: "Åekil 5.1. Tam otomatik MLOps pipeline'Ä±mÄ±z"
      }
    ]
  }
];
